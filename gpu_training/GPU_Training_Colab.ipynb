{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU-Accelerated Fire & Water Training (Google Colab)\n",
    "\n",
    "This notebook runs **1000+ parallel environments on GPU** for massive speedup.\n",
    "\n",
    "## Key Features:\n",
    "- **Pure GPU Physics**: All game logic runs on GPU\n",
    "- **Massive Parallelism**: Train 1000+ environments simultaneously\n",
    "- **50-100x Speedup**: Compared to CPU-based training\n",
    "- **Compatible Checkpoints**: Works with visualize.py\n",
    "- **Efficient Memory**: Pre-allocated GPU buffers\n",
    "\n",
    "## Expected Performance:\n",
    "- **CPU Training**: ~100-200 steps/sec (8-24 envs)\n",
    "- **GPU Training**: ~10,000-50,000 steps/sec (1024+ envs)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone Repository and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the GPU training branch\n",
    "!git clone -b gpu-training https://github.com/Ben-jpg-del/CalHacks.git\n",
    "%cd CalHacks\n",
    "\n",
    "print(\"\\n‚úÖ Repository cloned!\")\n",
    "print(\"Current directory:\", !pwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (PyTorch should already be on Colab)\n",
    "!pip install wandb -q\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Check GPU\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n‚úÖ GPU DETECTED\")\n",
    "    print(\"GPU Device:\", torch.cuda.get_device_name(0))\n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU Memory: {total_mem:.1f} GB\")\n",
    "    \n",
    "    # Check if L4 or T4\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    if 'L4' in gpu_name:\n",
    "        print(\"\\nüöÄ L4 GPU DETECTED - Excellent for training!\")\n",
    "        print(\"üí° Recommended: NUM_ENVS = 1024-2048\")\n",
    "    elif 'T4' in gpu_name:\n",
    "        print(\"\\n‚ö†Ô∏è  T4 GPU - Good but limited memory\")\n",
    "        print(\"üí° Recommended: NUM_ENVS = 512-1024\")\n",
    "    else:\n",
    "        print(f\"\\nüí° Recommended environments: {int(total_mem * 100)} (approx)\")\n",
    "else:\n",
    "    print(\"\\n‚ùå NO GPU DETECTED\")\n",
    "    print(\"Enable GPU: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration\n",
    "\n",
    "Adjust these parameters based on your GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# GPU TRAINING CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "# Environment settings\n",
    "NUM_ENVS = 1024          # Parallel environments (T4: use 512, L4: use 1024-2048)\n",
    "NUM_EPISODES = 5000      # Total episodes\n",
    "BATCH_SIZE = 1024        # Neural network batch size\n",
    "\n",
    "# Learning parameters\n",
    "LEARNING_RATE = 3e-4\n",
    "GAMMA = 0.99\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.01\n",
    "EPSILON_DECAY = 0.995\n",
    "\n",
    "# Buffer and update frequency\n",
    "BUFFER_CAPACITY = 1000000\n",
    "TARGET_UPDATE_FREQ = 1000\n",
    "\n",
    "# Checkpoint settings\n",
    "SAVE_DIR = 'checkpoints_gpu'\n",
    "SAVE_FREQ = 100          # Save every N episodes\n",
    "LOG_FREQ = 10            # Log every N episodes\n",
    "\n",
    "# Map distribution\n",
    "MAP_DISTRIBUTION = {\n",
    "    'tutorial': 0.5,\n",
    "    'tower': 0.3,\n",
    "    'map2': 0.2,\n",
    "}\n",
    "\n",
    "# Weights & Biases\n",
    "USE_WANDB = False\n",
    "WANDB_PROJECT = 'firewater-gpu'\n",
    "\n",
    "# Device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Parallel Environments: {NUM_ENVS}\")\n",
    "print(f\"Episodes: {NUM_EPISODES}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Save Directory: {SAVE_DIR}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Estimate memory usage\n",
    "if DEVICE == 'cuda':\n",
    "    obs_mem = NUM_ENVS * 52 * 4 / 1e6  # MB\n",
    "    buffer_mem = BUFFER_CAPACITY * 52 * 4 * 2 / 1e9  # GB\n",
    "    print(f\"\\nEstimated GPU Memory:\")\n",
    "    print(f\"  Observations: {obs_mem:.1f} MB\")\n",
    "    print(f\"  Replay Buffer: {buffer_mem:.2f} GB\")\n",
    "    print(f\"  Total (approx): ~{buffer_mem + 0.5:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test GPU Environment\n",
    "\n",
    "Quick test to ensure everything works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add gpu_training to path\n",
    "sys.path.insert(0, '/content/CalHacks/gpu_training')\n",
    "# Add parent CalHacks directory to path (for map imports)\n",
    "sys.path.insert(0, '/content/CalHacks')\n",
    "\n",
    "print(\"Python path:\")\n",
    "for p in sys.path[:3]:\n",
    "    print(f\"  {p}\")\n",
    "print()\n",
    "\n",
    "# Now imports should work\n",
    "from torch_env import TorchFireWaterEnv\n",
    "from map_config import LevelLibrary\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "print(\"\\nTesting GPU environment with 16 parallel instances...\\n\")\n",
    "\n",
    "# Create small test environment\n",
    "test_configs = [LevelLibrary.get_tutorial_level() for _ in range(16)]\n",
    "test_env = TorchFireWaterEnv(\n",
    "    num_envs=16,\n",
    "    level_configs=test_configs,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Environment created\")\n",
    "\n",
    "# Test reset\n",
    "fire_obs, water_obs = test_env.reset()\n",
    "print(f\"‚úÖ Reset successful\")\n",
    "print(f\"   Fire obs shape: {fire_obs.shape}\")\n",
    "print(f\"   Water obs shape: {water_obs.shape}\")\n",
    "print(f\"   Device: {fire_obs.device}\")\n",
    "\n",
    "# Test step\n",
    "fire_actions = torch.randint(0, 6, (16,), device=DEVICE)\n",
    "water_actions = torch.randint(0, 6, (16,), device=DEVICE)\n",
    "\n",
    "(fire_obs, water_obs), (fire_rewards, water_rewards), \\\n",
    "(fire_dones, water_dones), infos = test_env.step(fire_actions, water_actions)\n",
    "\n",
    "print(f\"\\n‚úÖ Step successful\")\n",
    "print(f\"   Rewards: fire={fire_rewards[0]:.2f}, water={water_rewards[0]:.2f}\")\n",
    "print(f\"   Dones: fire={fire_dones[0]}, water={water_dones[0]}\")\n",
    "print(f\"\\nüöÄ GPU environment is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setup Weights & Biases (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "    print(\"‚úÖ Logged in to W&B\")\n",
    "else:\n",
    "    print(\"W&B disabled. Set USE_WANDB=True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Agents\n",
    "\n",
    "Start GPU-accelerated training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Force reload the module to get latest code\nimport importlib\nimport sys\n\n# Remove cached module if it exists\nif 'train_gpu' in sys.modules:\n    del sys.modules['train_gpu']\n\n# Now import fresh\nfrom train_gpu import train_gpu\n\nprint(\"üöÄ Starting GPU-Accelerated Training...\")\nprint(\"=\" * 80)\n\ntrain_gpu(\n    num_envs=NUM_ENVS,\n    num_episodes=NUM_EPISODES,\n    batch_size=BATCH_SIZE,\n    learning_rate=LEARNING_RATE,\n    gamma=GAMMA,\n    epsilon_start=EPSILON_START,\n    epsilon_end=EPSILON_END,\n    epsilon_decay=EPSILON_DECAY,\n    target_update_freq=TARGET_UPDATE_FREQ,\n    buffer_capacity=BUFFER_CAPACITY,\n    save_dir=SAVE_DIR,\n    save_freq=SAVE_FREQ,\n    log_freq=LOG_FREQ,\n    device=DEVICE,\n    use_wandb=USE_WANDB,\n    wandb_project=WANDB_PROJECT,\n    map_distribution=MAP_DISTRIBUTION\n)\n\nprint(\"\\n‚úÖ Training complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. List Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(SAVE_DIR):\n",
    "    checkpoints = sorted([d for d in os.listdir(SAVE_DIR) if d.startswith('checkpoint_')])\n",
    "    \n",
    "    print(f\"Checkpoints in {SAVE_DIR}:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for cp in checkpoints:\n",
    "        cp_dir = os.path.join(SAVE_DIR, cp)\n",
    "        if os.path.isdir(cp_dir):\n",
    "            files = os.listdir(cp_dir)\n",
    "            fire_exists = 'fire_agent.pth' in files\n",
    "            water_exists = 'water_agent.pth' in files\n",
    "            status = \"‚úÖ\" if (fire_exists and water_exists) else \"‚ö†Ô∏è\"\n",
    "            print(f\"{status} {cp}\")\n",
    "    \n",
    "    final_dir = os.path.join(SAVE_DIR, 'final')\n",
    "    if os.path.exists(final_dir):\n",
    "        print(f\"\\n‚úÖ Final checkpoint saved\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Total checkpoints: {len(checkpoints)}\")\n",
    "else:\n",
    "    print(f\"No checkpoints found in {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Download Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# Zip checkpoints\n",
    "shutil.make_archive('checkpoints_gpu', 'zip', SAVE_DIR)\n",
    "\n",
    "print(\"‚úÖ Checkpoints zipped!\")\n",
    "print(f\"\\nFile: checkpoints_gpu.zip\")\n",
    "print(f\"Size: {os.path.getsize('checkpoints_gpu.zip') / 1e6:.1f} MB\")\n",
    "print(\"\\nDownloading...\")\n",
    "\n",
    "# Auto-download\n",
    "files.download('checkpoints_gpu.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Locally (Instructions)\n",
    "\n",
    "To visualize your trained agents:\n",
    "\n",
    "1. **Download** `checkpoints_gpu.zip` from Colab (ran in cell above)\n",
    "2. **Extract** to your local CalHacks repository\n",
    "3. **Run visualization**:\n",
    "\n",
    "```bash\n",
    "# From CalHacks directory\n",
    "python visualize.py trained checkpoints_gpu/final/fire_agent.pth checkpoints_gpu/final/water_agent.pth --map tutorial\n",
    "\n",
    "# Try different maps\n",
    "python visualize.py trained checkpoints_gpu/final/fire_agent.pth checkpoints_gpu/final/water_agent.pth --map tower\n",
    "python visualize.py trained checkpoints_gpu/final/fire_agent.pth checkpoints_gpu/final/water_agent.pth --map map2\n",
    "```\n",
    "\n",
    "The GPU-trained models are fully compatible with the existing visualization system!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Expected speedup vs CPU training:\n",
    "\n",
    "| Method | Envs | Steps/sec | Time for 5000 eps |\n",
    "|--------|------|-----------|-------------------|\n",
    "| CPU Sequential | 24 | ~200 | ~100 hours |\n",
    "| CPU Multiprocessing | 24 | ~1,000 | ~20 hours |\n",
    "| **GPU (This)** | **1024** | **~20,000** | **~1-2 hours** |\n",
    "\n",
    "With GPU training on Colab, you can achieve in **1-2 hours** what would take **100+ hours** on CPU!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}